# 神经网络基础

## 1.创建网络层

1. **nn.sequantial()**：

- 优势：代码少，直观

```python
net= nn.sequential(xxx,xxx,xxx)
#xxx是各种层
```

**module**: 任何一个层或者神经网络都应该是module的子类



2. **或者自定义一个nn模型：**

- 优势：可以灵活的进行大量自定义的init和forward计算

```python
class Model(nn.Module):
    def __init__(self):   #定义属性
        super().__init()  #调用Module这个父类，会把需要的内部参数设好
	def forward(self,x):
        
        
```



3.还有混合搭配，只要是nn的子类模型，都能作为input放进sequential或者model中作为模型的一部分以嵌套

---

## 2.参数管理

```python
model[x].state_dict() #参数访问，模型的第x个layer的参数
type(model[x].bias) #参数类型,假设第x层有一个bias
model[x].bias #具体告诉参数是什么和其他信息
model[x].bias.data #bias的参数是多少
model[x].weight.grad==None #访问weight的梯度，检查是否为None
*[(name.param.shape) for name,param in net[x].named_parameters()] #返回net第x层的参数名和shape，并连起来，稍后可直接print
*[(name.param.shape) for name,param in net.named_parameters()] #与上同理，返回net的所有层
net.state_dict()['xxx'].data #在知道某层中有什么参数后，将其状态中的当前参数取出，'xxx'是参数名
print(net) #直接打印net的layer是怎么样的结构

```

### 手动定义初始化函数

<img src="C:\Users\盛杨\AppData\Roaming\Typora\typora-user-images\image-20231128220318950.png" alt="image-20231128220318950" style="zoom:33%;" />

<img src="C:\Users\盛杨\AppData\Roaming\Typora\typora-user-images\image-20231128220330437.png" alt="image-20231128220330437" style="zoom:45%;" />

```python
net.apply(init_xx) #将模型应用我们定义的初始化函数init_xx
```

